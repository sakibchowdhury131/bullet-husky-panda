{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401d47c-63ec-44c7-a8bc-a82e9a71a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyrealsense2 open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d95e90c-66c9-4b65-8232-1ece3b2804a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in ./env/lib/python3.10/site-packages (from opencv-python) (2.2.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25afe2c-0df9-46e8-b83f-f65cfa8addd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "# Initialize RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    " \n",
    "# Enable depth and color streams\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "# Get depth scale for converting depth values to meters\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# Intrinsic parameters\n",
    "intrinsics = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()\n",
    "fx, fy, cx, cy = intrinsics.fx, intrinsics.fy, intrinsics.ppx, intrinsics.ppy\n",
    "\n",
    "def depth_to_3d(x, y, depth):\n",
    "    \"\"\" Convert pixel (x, y) and depth to 3D world coordinates. \"\"\"\n",
    "    z = depth * depth_scale\n",
    "    if z == 0:  # Ignore invalid depth points\n",
    "        return None\n",
    "    X = (x - cx) * z / fx\n",
    "    Y = (y - cy) * z / fy\n",
    "    return np.array([X, Y, z])\n",
    "\n",
    "def detect_ball(color_image):\n",
    "    \"\"\" Detect a ball in the color image using color thresholding. \"\"\"\n",
    "    hsv = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define color range for the ball (adjust as needed)\n",
    "    lower_red = np.array([0, 140, 180])\n",
    "    upper_red = np.array([20, 230, 255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        (x, y), radius = cv2.minEnclosingCircle(largest_contour)\n",
    "        if radius > 5:  # Filter out small noise\n",
    "            return int(x), int(y), int(radius)\n",
    "    return None\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert frames to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Detect the ball\n",
    "        ball = detect_ball(color_image)\n",
    "        if ball:\n",
    "            x, y, radius = ball\n",
    "\n",
    "            # Get depth value at the detected position\n",
    "            depth_value = depth_image[y, x]\n",
    "            ball_position = depth_to_3d(x, y, depth_value)\n",
    "\n",
    "            if ball_position is not None:\n",
    "                print(f\"Ball detected at: {ball_position}\")\n",
    "\n",
    "                # Draw the detected ball on the color image\n",
    "                cv2.circle(color_image, (x, y), radius, (0, 255, 0), 2)\n",
    "                cv2.putText(color_image, f\"3D: {ball_position[0]:.2f}, {ball_position[1]:.2f}, {ball_position[2]:.2f}\", \n",
    "                            (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Show images\n",
    "        cv2.imshow(\"Color Image\", color_image)\n",
    "        # cv2.imshow(\"Depth Image\", cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET))\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32ac22-74fe-4f1c-914c-a4cb1746888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "def get_hsv_value(event, x, y, flags, param):\n",
    "    \"\"\"Callback function to get HSV values on mouse click.\"\"\"\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Left mouse click\n",
    "        hsv_pixel = hsv[y, x]  # Get HSV value at clicked position\n",
    "        print(f\"HSV at ({x}, {y}): {hsv_pixel}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a new frame\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "        \n",
    "        # Convert frame to numpy array\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        hsv = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)  # Convert to HSV\n",
    "        \n",
    "        # Display image\n",
    "        cv2.imshow(\"RealSense Camera\", color_image)\n",
    "        cv2.setMouseCallback(\"RealSense Camera\", get_hsv_value)  # Set mouse click event\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Stop the RealSense pipeline\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4a37d-e9a4-4d5e-af4d-9af543673df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving object detected at: [ 0.02195311 -0.05009727  3.18400015]\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Initialize RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Enable depth and color streams\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "# Get depth scale for converting depth values to meters\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# Get camera intrinsics\n",
    "intrinsics = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()\n",
    "fx, fy, cx, cy = intrinsics.fx, intrinsics.fy, intrinsics.ppx, intrinsics.ppy\n",
    "\n",
    "# Function to convert depth to 3D world coordinates\n",
    "def depth_to_3d(x, y, depth):\n",
    "    z = depth * depth_scale\n",
    "    if z == 0:  # Ignore invalid depth points\n",
    "        return None\n",
    "    X = (x - cx) * z / fx\n",
    "    Y = (y - cy) * z / fy\n",
    "    return np.array([X, Y, z])\n",
    "\n",
    "# Initialize previous frame for motion detection\n",
    "previous_gray = None\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Capture frames\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # If first frame, store and continue\n",
    "        if previous_gray is None:\n",
    "            previous_gray = gray\n",
    "            continue\n",
    "\n",
    "        # Compute absolute difference between current and previous frame\n",
    "        frame_diff = cv2.absdiff(previous_gray, gray)\n",
    "\n",
    "        # Apply threshold to highlight differences\n",
    "        _, thresh = cv2.threshold(frame_diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours of the moving regions\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            (x, y), radius = cv2.minEnclosingCircle(largest_contour)\n",
    "            \n",
    "            if radius > 10:  # Filter out small noise\n",
    "                x, y, radius = int(x), int(y), int(radius)\n",
    "\n",
    "                # Get depth value at detected position\n",
    "                depth_value = depth_image[y, x]\n",
    "                ball_position = depth_to_3d(x, y, depth_value)\n",
    "\n",
    "                if ball_position is not None:\n",
    "                    print(f\"Moving object detected at: {ball_position}\")\n",
    "\n",
    "                    # Draw detection circle\n",
    "                    cv2.circle(color_image, (x, y), radius, (0, 255, 0), 2)\n",
    "                    cv2.putText(color_image, f\"3D: {ball_position[0]:.2f}, {ball_position[1]:.2f}, {ball_position[2]:.2f}\", \n",
    "                                (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Update previous frame\n",
    "        previous_gray = gray.copy()\n",
    "\n",
    "        # Display results\n",
    "        cv2.imshow(\"Color Image\", color_image)\n",
    "        cv2.imshow(\"Motion Mask\", thresh)\n",
    "\n",
    "        # Exit on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
